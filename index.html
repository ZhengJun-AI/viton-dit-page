<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="VITON-DiT">
  <meta name="keywords" content="Virtual Try-on, Customizable Generation, Diffusion Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VITON-DiT</title>


  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">VITON-DiT: Learning In-the-Wild Video Try-On from Human Dance Videos via Diffusion Transformers</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Jun Zheng<sup>1 <sup> </a>&nbsp</a>&nbsp  
            </span>
            <span class="author-block">
              Fuwei Zhao<sup>2<sup> </a>&nbsp</a>&nbsp  
            </span>
            
            <span class="author-block">
              Youjiang Xu<sup>2<sup>  </a></a>&nbsp</a>&nbsp  
            </span>
            <span class="author-block">
              Xin Dong<sup>2</sup>  </a></a>&nbsp</a>&nbsp  
            </span>
            <span class="author-block">
              Xiaodan Liang<sup>1</sup>  </a></a>&nbsp</a>&nbsp  
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Sun Yat-Sen University</a>&nbsp</a>&nbsp  </span>
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>2</sup>ByteDance China</a>&nbsp</a>&nbsp  </span>
            
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2405.18326"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" disabled>
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" disabled>
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" disabled>
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero is-light is-small">
  <div class="hero-body">
      <div class="container">
          <div class="item item-steve">
          <img src="./generate_images/images/teaser/fig_3_teaser_v3.png"  width="100%">
        </div>
      </div>
    </div>
  </section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Video try-on stands as a promising area for its tremendous real-world potential. Prior works are limited to transferring product clothing images onto person videos with simple poses and backgrounds, while underperforming on casually captured videos. 
            Recently, Sora revealed the scalability of Diffusion Transformer (DiT) in generating lifelike videos featuring real-world scenarios. Inspired by this, we explore and propose the first DiT-based video try-on framework for practical in-the-wild applications, named <b>VITON-DiT</b>. Specifically, VITON-DiT consists of a garment extractor, a Spatial-Temporal denoising  DiT, and an identity preservation ControlNet. 
            To faithfully recover the clothing details, the extracted garment features are fused with the self-attention outputs of the denoising DiT and the ControlNet. We also introduce novel random selection strategies during training and an Interpolated Auto-Regressive (IAR) technique at inference to facilitate long video generation. Unlike existing attempts that require the laborious and restrictive construction of a paired training dataset, severely limiting their scalability, VITON-DiT alleviates this by relying solely on unpaired human dance videos and a carefully designed multi-stage training strategy. 
            Furthermore, we curate a challenging benchmark dataset to evaluate the performance of casual video try-on. Extensive experiments demonstrate the superiority of VITON-DiT in generating spatio-temporal consistent try-on results for in-the-wild videos with complicated human poses.
          </p>
          </p>
        </div>
      </div>
    </div>

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

         <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3" style="text-align: center;">Adapting to Different Clothing Styles and Scenes</h2>
              <div class="content has-text-justified">
                <p>
                  VITON-DiT can handle complex clothing and backgrounds even with less accurate pose conditions.
                </p>
              </div>
            <h2 class="title is-4" style="text-align: center;">Simple Clothing and Static Backgrounds</h2>
            <div class="columns is-centered is-multiline">
              <div class="column">
                <video width="960" height="720" controls>
                  <source src="generate_images/videos/21.mp4" type="video/MP4" width="960" height="384">
                </video>
              </div>
              <div class="column">
                <video width="960" height="720" controls>
                  <source src="generate_images/videos/22.mp4" type="video/MP4" width="960" height="384">
                </video>
              </div>
            </div>

            <h2 class="title is-4" style="text-align: center;">Challenging Clothing and In-the-Wild Scenes</h2>
            <div class="columns is-centered is-multiline">
              <div class="column">
                <video width="960" height="720" controls>
                  <source src="generate_images/videos/13.mp4" type="video/MP4" width="960" height="384">
                </video>
              </div>
              <div class="column">
                <video width="960" height="720" controls>
                  <source src="generate_images/videos/24.mp4" type="video/MP4" width="960" height="384">
                </video>
              </div>
            </div>
            <div class="columns is-centered is-multiline">
              <div class="column">
                <video width="960" height="720" controls>
                  <source src="generate_images/videos/3.mp4" type="video/MP4" width="960" height="384">
                </video>
              </div>
              <div class="column">
                <video width="960" height="720" controls>
                  <source src="generate_images/videos/2.mp4" type="video/MP4" width="960" height="384">
                </video>
              </div>
            </div>


        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3" style="text-align: center;">Adapting to Different Perspective and Human Poses</h2>
              <div class="content has-text-justified">
                <p>
                  Unlike previous video try-on methods limited to simple human poses and slow movement, Our VITON-DiT can perform try-on tasks for unusual viewpoints and complicated poses.
                </p>
              </div>            
              <!-- <h2 class="title is-4" style="text-align: center;">Simple Poses and Slow Motion</h2> -->
  
              <h2 class="title is-4" style="text-align: center;">Rare Perspective and Complex Body Movements</h2>
              <div class="columns is-centered is-multiline">
                <div class="column">
                  <video width="960" height="720" controls>
                    <source src="generate_images/videos/20.mp4" type="video/MP4" width="960" height="384">
                  </video>
                </div>
                <div class="column">
                  <video width="960" height="720" controls>
                    <source src="generate_images/videos/14.mp4" type="video/MP4" width="960" height="384">
                  </video>
                </div>
              </div>
              <div class="columns is-centered is-multiline">
                <div class="column">
                  <video width="960" height="720" controls>
                    <source src="generate_images/videos/11.mp4" type="video/MP4" width="960" height="384">
                  </video>
                </div>
                <div class="column">
                  <video width="960" height="720" controls>
                    <source src="generate_images/videos/10.mp4" type="video/MP4" width="960" height="384">
                  </video>
                </div>
              </div>


            <div class="columns is-centered">
              <div class="column is-full-width">
                <h2 class="title is-3" style="text-align: center;">Framework</h2>
                  <div class="content has-text-justified">
                    <p>
                      Overview of the proposed VITON-DiT. 
                      <p>(a) The architecture contains three components with the following tasks. (1) <i>Denoising DiT</i> : generating latent representation of video contents via a chain of Spatio-Temporal (ST-) DiT blocks. (2) <i>ID ControlNet</i> : producing feature residual for the Denoising DiT to preserve the reference person's identity, pose, and background. (3) <i>Garment Extractor</i> : obtaining and delivering garment features into the Denoising DiT and the ControlNet via Attention Fusion, thus recovering detailed clothing textures in the generated try-on video. </p>
                      <p>(b) Illustrated Attention Fusion: integrating person denoising features and extracted garment features using additive attention. This operation is utilized in both the Denoising DiT and the ID ControlNet.</p>
                      
                    </p>
                  </div>
                <div class="columns is-centered has-text-centered">
                  <div class="column">
                    <div class="item item-steve">
                      <img src="./generate_images/images/VITON-DiT.png"  width="90%">
                    </div>   
                      
                  </div>
                </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{zheng2024vitondit,
      title={VITON-DiT: Learning In-the-Wild Video Try-On from Human Dance Videos via Diffusion Transformers},
      author={Zheng, Jun and Zhao, Fuwei and Xu, Youjiang and Dong, Xin and Liang, Xiaodan},
      journal={arXiv preprint},
      year={2024}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      
    </div>
    <div class="columns is-centered">
      <div class="content">
        <p>
          The template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
        </p>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
